Despite the prevalent ideal among scientists that science is an ever-changing and self-correcting enterprise, the current scientific publishing system in use worldwide makes it difficult to enact public corrections to published scientific works. The downloadable PDF format is static, and formal corrections, expressions of concern, and retractions are rare, even for papers with widely agreed-upon inconsistencies that warrant retraction (as seen, for example, on pubpeer). To advocate for reforms in this publishing system, metascientists often cite post-retraction citations as an example of science that “does not correct itself”. However, it is not safe to assume that all post-retraction citations are examples of scientists continuing to be led astray by unreliable, retracted work. Some citations are to argue the work is in fact sound despite the retraction, or even that the work is a good example of poor scientific practices to avoid—in both of these cases, the retraction is acknowledged by the author of the citing document. A better measure of the inefficiency of the current “retraction” model of correction of the scientific record would be the rate or number of post-retraction citations that 1) do not acknowledge the paper is retracted and 2) use the invalidated results of the retracted paper in a meaningful way that then invalidates their work. I am building an algorithm to help produce a measure of the first group: papers that cite a retracted paper and do not acknowledge that it is retracted.
